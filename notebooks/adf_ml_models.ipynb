{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Applied Data Finance ML Models - Model Registry\n",
        "\n",
        "This notebook trains the three ML models required for the Applied Data Finance Intelligence Agent:\n",
        "- **Payment Volume Forecasting** - Predict future monthly servicing cash-flow\n",
        "- **Borrower Risk Classification** - Identify borrowers likely to become delinquent\n",
        "- **Collection Promise-to-Pay Prediction** - Estimate the probability that a collection event results in a valid promise\n",
        "\n",
        "All models are registered to Snowflake Model Registry and exposed to the agent through `sql/ml/07_create_model_wrapper_functions.sql`.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "**Required Packages** (configured automatically):\n",
        "- `snowflake-ml-python`\n",
        "- `scikit-learn`\n",
        "- `xgboost`\n",
        "- `matplotlib`\n",
        "\n",
        "**Database Context:**\n",
        "- **Database:** ADF_INTELLIGENCE  \n",
        "- **Schema:** ANALYTICS  \n",
        "- **Warehouse:** ADF_SI_WH\n",
        "\n",
        "**Note:** This notebook uses Snowflake Model Registry. Ensure you have appropriate permissions to create and register models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Python packages\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import Snowpark\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import snowflake.snowpark.functions as F\n",
        "import snowflake.snowpark.types as T\n",
        "from snowflake.snowpark import Window\n",
        "\n",
        "# Import Snowpark ML\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.pipeline import Pipeline\n",
        "from snowflake.ml.modeling.linear_model import LinearRegression, LogisticRegression\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, accuracy_score, roc_auc_score\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "print(\"✅ Packages imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to Snowflake\n",
        "\n",
        "Get the active session and set context to the Applied Data Finance database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get active Snowflake session\n",
        "session = get_active_session()\n",
        "\n",
        "# Set context\n",
        "session.use_database('ADF_INTELLIGENCE')\n",
        "session.use_schema('ANALYTICS')\n",
        "session.use_warehouse('ADF_SI_WH')\n",
        "\n",
        "print(f\"✅ Connected - Role: {session.get_current_role()}\")\n",
        "print(f\"   Warehouse: {session.get_current_warehouse()}\")\n",
        "print(f\"   Database.Schema: {session.get_fully_qualified_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 1: Payment Volume Forecasting\n",
        "\n",
        "Predict future monthly cash collections using historical payment activity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Revenue Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get monthly payment volume data with servicing features\n",
        "payment_volume_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    DATE_TRUNC('month', payment_date)::DATE AS payment_month,\n",
        "    MONTH(payment_date) AS month_num,\n",
        "    YEAR(payment_date) AS year_num,\n",
        "    SUM(amount)::FLOAT AS total_payment_amount,\n",
        "    COUNT(DISTINCT loan_id)::FLOAT AS loan_count,\n",
        "    AVG(amount)::FLOAT AS avg_payment_amount,\n",
        "    COUNT_IF(late_fee_applied)::FLOAT AS late_payment_count\n",
        "FROM RAW.PAYMENT_HISTORY\n",
        "WHERE payment_date >= DATEADD('month', -36, CURRENT_DATE())\n",
        "GROUP BY 1,2,3\n",
        "ORDER BY payment_month\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Payment volume data: {payment_volume_df.count()} months\")\n",
        "payment_volume_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Data and Train Revenue Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (last 6 months for testing)\n",
        "train_payment_volume = payment_volume_df.filter(F.col(\"PAYMENT_MONTH\") < F.dateadd(\"month\", F.lit(-6), F.current_date()))\n",
        "test_payment_volume = payment_volume_df.filter(F.col(\"PAYMENT_MONTH\") >= F.dateadd(\"month\", F.lit(-6), F.current_date()))\n",
        "\n",
        "# Drop PAYMENT_MONTH (DATE type not supported in pipeline)\n",
        "train_payment_volume = train_payment_volume.drop(\"PAYMENT_MONTH\")\n",
        "test_payment_volume = test_payment_volume.drop(\"PAYMENT_MONTH\")\n",
        "\n",
        "# Create pipeline\n",
        "payment_volume_pipeline = Pipeline([\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"MONTH_NUM\", \"LOAN_COUNT\", \"AVG_PAYMENT_AMOUNT\", \"LATE_PAYMENT_COUNT\"],\n",
        "        output_cols=[\"MONTH_NUM_SCALED\", \"LOAN_COUNT_SCALED\", \"AVG_PAYMENT_AMOUNT_SCALED\", \"LATE_PAYMENT_COUNT_SCALED\"]\n",
        "    )),\n",
        "    (\"LinearRegression\", LinearRegression(\n",
        "        label_cols=[\"TOTAL_PAYMENT_AMOUNT\"],\n",
        "        output_cols=[\"PREDICTED_PAYMENT_AMOUNT\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "payment_volume_pipeline.fit(train_payment_volume)\n",
        "print(\"✅ Payment volume forecasting model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Revenue Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test set\n",
        "test_predictions = payment_volume_pipeline.predict(test_payment_volume)\n",
        "\n",
        "# Calculate metrics\n",
        "mae = mean_absolute_error(df=test_predictions, y_true_col_names=\"TOTAL_PAYMENT_AMOUNT\", y_pred_col_names=\"PREDICTED_PAYMENT_AMOUNT\")\n",
        "mse = mean_squared_error(df=test_predictions, y_true_col_names=\"TOTAL_PAYMENT_AMOUNT\", y_pred_col_names=\"PREDICTED_PAYMENT_AMOUNT\")\n",
        "rmse = mse ** 0.5\n",
        "\n",
        "metrics = {\"mae\": round(mae, 2), \"rmse\": round(rmse, 2)}\n",
        "print(f\"Model metrics: {metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg = Registry(session)\n",
        "reg.log_model(\n",
        "    model=payment_volume_pipeline,\n",
        "    model_name=\"PAYMENT_VOLUME_FORECASTER\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts monthly payment volume based on servicing activity using Linear Regression\",\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Payment volume model registered to Model Registry as PAYMENT_VOLUME_FORECASTER\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 2: Borrower Risk Classification\n",
        "\n",
        "Classify borrowers as likely to become delinquent based on recent servicing performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Churn Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get borrower features for delinquency risk classification\n",
        "borrower_risk_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    c.customer_id,\n",
        "    c.risk_segment AS borrower_segment,\n",
        "    c.employment_status,\n",
        "    c.annual_income::FLOAT AS annual_income,\n",
        "    c.credit_score::FLOAT AS credit_score,\n",
        "    COUNT(DISTINCT l.loan_id)::FLOAT AS total_loans,\n",
        "    SUM(l.outstanding_principal)::FLOAT AS outstanding_principal,\n",
        "    COUNT_IF(l.servicing_status = 'DELINQUENT')::FLOAT AS delinquent_loans,\n",
        "    AVG(p.amount)::FLOAT AS avg_payment_amount,\n",
        "    COUNT_IF(p.nsf_flag)::FLOAT AS nsf_events,\n",
        "    (COUNT_IF(l.servicing_status = 'DELINQUENT') > 0)::BOOLEAN AS is_delinquent\n",
        "FROM RAW.CUSTOMERS c\n",
        "LEFT JOIN RAW.LOAN_ACCOUNTS l ON c.customer_id = l.customer_id\n",
        "LEFT JOIN RAW.PAYMENT_HISTORY p ON l.loan_id = p.loan_id\n",
        "GROUP BY 1,2,3,4,5\n",
        "HAVING COUNT(DISTINCT l.loan_id) > 0\n",
        "LIMIT 10000\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Borrower risk data: {borrower_risk_df.count()} borrowers\")\n",
        "borrower_risk_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Churn Classification Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (80/20)\n",
        "train_risk, test_risk = borrower_risk_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop CUSTOMER_ID\n",
        "train_risk = train_risk.drop(\"CUSTOMER_ID\")\n",
        "test_risk = test_risk.drop(\"CUSTOMER_ID\")\n",
        "\n",
        "# Create pipeline with preprocessing and classification\n",
        "borrower_risk_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"BORROWER_SEGMENT\", \"EMPLOYMENT_STATUS\"],\n",
        "        output_cols=[\"BORROWER_SEGMENT_ENCODED\", \"EMPLOYMENT_STATUS_ENCODED\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"IS_DELINQUENT\"],\n",
        "        output_cols=[\"RISK_PREDICTION\"],\n",
        "        n_estimators=200,\n",
        "        max_depth=12\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "borrower_risk_pipeline.fit(train_risk)\n",
        "print(\"✅ Borrower risk classification model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Churn Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "borrower_risk_predictions = borrower_risk_pipeline.predict(test_risk)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(df=borrower_risk_predictions, y_true_col_names=\"IS_DELINQUENT\", y_pred_col_names=\"RISK_PREDICTION\")\n",
        "risk_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Borrower risk model metrics: {risk_metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg.log_model(\n",
        "    model=borrower_risk_pipeline,\n",
        "    model_name=\"BORROWER_RISK_MODEL\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts borrower delinquency risk using Random Forest on servicing features\",\n",
        "    metrics=risk_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Borrower risk model registered to Model Registry as BORROWER_RISK_MODEL\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 3: Collection Promise-to-Pay Prediction\n",
        "\n",
        "Predict the probability that a collection interaction results in a valid promise to pay.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Device Deployment Success Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get collection interaction features for promise-to-pay prediction\n",
        "collection_ptp_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    ce.collection_id,\n",
        "    ce.loan_id,\n",
        "    ce.customer_id,\n",
        "    ce.event_type,\n",
        "    ce.severity,\n",
        "    ce.outcome,\n",
        "    COALESCE(ce.promise_amount, 0)::FLOAT AS promise_amount,\n",
        "    DATEDIFF('day', ce.event_timestamp::DATE, CURRENT_DATE()) AS event_age_days,\n",
        "    loans.delinquency_bucket,\n",
        "    loans.servicing_status,\n",
        "    loans.outstanding_principal::FLOAT AS outstanding_principal,\n",
        "    (ce.promise_to_pay_date IS NOT NULL OR ce.outcome = 'PROMISE_TO_PAY')::BOOLEAN AS ptp_success\n",
        "FROM RAW.COLLECTION_EVENTS ce\n",
        "JOIN RAW.LOAN_ACCOUNTS loans ON ce.loan_id = loans.loan_id\n",
        "WHERE ce.event_timestamp >= DATEADD('month', -18, CURRENT_TIMESTAMP())\n",
        "LIMIT 30000\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Collection interactions: {collection_ptp_df.count()} rows\")\n",
        "collection_ptp_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Conversion Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "train_ptp, test_ptp = collection_ptp_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop identifier columns\n",
        "train_ptp = train_ptp.drop(\"COLLECTION_ID\", \"LOAN_ID\", \"CUSTOMER_ID\")\n",
        "test_ptp = test_ptp.drop(\"COLLECTION_ID\", \"LOAN_ID\", \"CUSTOMER_ID\")\n",
        "\n",
        "# Create pipeline\n",
        "collection_ptp_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"EVENT_TYPE\", \"SEVERITY\", \"OUTCOME\", \"DELINQUENCY_BUCKET\", \"SERVICING_STATUS\"],\n",
        "        output_cols=[\"EVENT_TYPE_ENC\", \"SEVERITY_ENC\", \"OUTCOME_ENC\", \"DELINQUENCY_BUCKET_ENC\", \"SERVICING_STATUS_ENC\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", LogisticRegression(\n",
        "        label_cols=[\"PTP_SUCCESS\"],\n",
        "        output_cols=[\"PTP_PREDICTION\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "collection_ptp_pipeline.fit(train_ptp)\n",
        "print(\"✅ Collection promise-to-pay model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Conversion Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "ptp_predictions = collection_ptp_pipeline.predict(test_ptp)\n",
        "\n",
        "# Calculate accuracy\n",
        "ptp_accuracy = accuracy_score(\n",
        "    df=ptp_predictions,\n",
        "    y_true_col_names=\"PTP_SUCCESS\",\n",
        "    y_pred_col_names=\"PTP_PREDICTION\"\n",
        ")\n",
        "ptp_metrics = {\"accuracy\": round(ptp_accuracy, 4)}\n",
        "print(f\"Promise-to-pay model metrics: {ptp_metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg.log_model(\n",
        "    model=collection_ptp_pipeline,\n",
        "    model_name=\"COLLECTION_SUCCESS_MODEL\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts the probability that a collection interaction results in a promise to pay\",\n",
        "    metrics=ptp_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Collection PTP model registered to Model Registry as COLLECTION_SUCCESS_MODEL\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Verify Models in Registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show all models in the registry\n",
        "print(\"Models in registry:\")\n",
        "reg.show_models()\n",
        "\n",
        "# Show versions for payment volume model\n",
        "print(\"\\nPayment Volume Forecaster versions:\")\n",
        "reg.get_model(\"PAYMENT_VOLUME_FORECASTER\").show_versions()\n",
        "\n",
        "# Show versions for borrower risk model  \n",
        "print(\"\\nBorrower Risk Model versions:\")\n",
        "reg.get_model(\"BORROWER_RISK_MODEL\").show_versions()\n",
        "\n",
        "# Show versions for collection success model\n",
        "print(\"\\nCollection Success Model versions:\")\n",
        "reg.get_model(\"COLLECTION_SUCCESS_MODEL\").show_versions()\n",
        "\n",
        "print(\"\\n✅ All models registered and ready to add to the Intelligence Agent\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Test Model Inference\n",
        "\n",
        "Test calling each model to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test payment volume forecast on recent data\n",
        "payment_volume_model = reg.get_model(\"PAYMENT_VOLUME_FORECASTER\").default\n",
        "recent_payment_volume = payment_volume_df.limit(3).drop(\"PAYMENT_MONTH\")\n",
        "payment_volume_preds = payment_volume_model.run(recent_payment_volume, function_name=\"predict\")\n",
        "print(\"Payment volume predictions:\")\n",
        "payment_volume_preds.select(\"TOTAL_PAYMENT_AMOUNT\", \"PREDICTED_PAYMENT_AMOUNT\").show()\n",
        "\n",
        "# Test borrower risk prediction on sample borrowers\n",
        "borrower_risk_model = reg.get_model(\"BORROWER_RISK_MODEL\").default\n",
        "sample_borrowers = borrower_risk_df.limit(5).drop(\"CUSTOMER_ID\")\n",
        "borrower_risk_preds = borrower_risk_model.run(sample_borrowers, function_name=\"predict\")\n",
        "print(\"\\nBorrower risk predictions:\")\n",
        "borrower_risk_preds.select(\"IS_DELINQUENT\", \"RISK_PREDICTION\").show()\n",
        "\n",
        "# Test collection promise-to-pay prediction\n",
        "collection_success_model = reg.get_model(\"COLLECTION_SUCCESS_MODEL\").default\n",
        "sample_collections = collection_ptp_df.limit(5).drop(\"COLLECTION_ID\", \"LOAN_ID\", \"CUSTOMER_ID\")\n",
        "collection_success_preds = collection_success_model.run(sample_collections, function_name=\"predict\")\n",
        "print(\"\\nCollection promise-to-pay predictions:\")\n",
        "collection_success_preds.select(\"PTP_SUCCESS\", \"PTP_PREDICTION\").show()\n",
        "\n",
        "print(\"\\n✅ All models tested successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Next Steps\n",
        "\n",
        "## Add Models to Intelligence Agent\n",
        "\n",
        "**Option 1: Using the SQL Script (Easiest)**\n",
        "Run `sql/agent/08_create_intelligence_agent.sql` which automatically configures all 3 ML models.\n",
        "\n",
        "**Option 2: Manual Configuration in Snowsight**\n",
        "1. In Snowsight → AI & ML → Agents → ADF_INTELLIGENCE_AGENT\n",
        "2. Go to Tools → + Add → Function\n",
        "3. Add each model wrapper procedure:\n",
        "   - **PREDICT_PAYMENT_VOLUME** (from `sql/ml/07_create_model_wrapper_functions.sql`)\n",
        "   - **PREDICT_BORROWER_RISK** (from `sql/ml/07_create_model_wrapper_functions.sql`)\n",
        "   - **PREDICT_COLLECTION_SUCCESS** (from `sql/ml/07_create_model_wrapper_functions.sql`)\n",
        "\n",
        "## Example Questions for Agent\n",
        "\n",
        "- \"Predict cash collections for the next 6 months\"\n",
        "- \"Which borrowers are at high risk of delinquency?\"\n",
        "- \"What is the promise-to-pay conversion probability for this collection event?\"\n",
        "- \"Which segments contribute most to upcoming payment volume?\"\n",
        "\n",
        "The models will now be available as tools your agent can use!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "snowflake": {
      "packages": [
        "snowflake-ml-python",
        "scikit-learn",
        "xgboost",
        "matplotlib"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
