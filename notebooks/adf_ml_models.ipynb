{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Applied Data Finance ML Models\n",
        "\n",
        "This Snowflake Notebook trains and registers three models used by the ADF Intelligence Agent:\n",
        "\n",
        "1. Payment volume forecast for servicing cash-flow planning\n",
        "2. Borrower risk classification to flag likely delinquencies\n",
        "3. Collections promise-to-pay success estimator\n",
        "\n",
        "Run the cells sequentially after executing the SQL setup scripts so the underlying tables contain synthetic data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.snowpark.functions import col, date_trunc\n",
        "from snowflake.ml.modeling.linear_model import LinearRegression\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.linear_model import LogisticRegression\n",
        "from snowflake.ml.registry import Registry\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "session = get_active_session()\n",
        "reg = Registry(session)\n",
        "\n",
        "DATABASE = \"ADF_INTELLIGENCE\"\n",
        "SCHEMA = \"RAW\"\n",
        "ANALYTICS_SCHEMA = \"ANALYTICS\"\n",
        "WAREHOUSE = \"ADF_SI_WH\"\n",
        "\n",
        "print(f\"Using database={DATABASE}, schema={SCHEMA}, warehouse={WAREHOUSE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Payment Volume Forecast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payment_sf = session.sql(\n",
        "    f\"\"\"\n",
        "    SELECT\n",
        "        DATE_TRUNC('month', payment_date) AS payment_month,\n",
        "        COUNT(DISTINCT loan_id) AS active_loans,\n",
        "        SUM(amount) AS total_payments\n",
        "    FROM {DATABASE}.{SCHEMA}.PAYMENT_HISTORY\n",
        "    GROUP BY 1\n",
        "    ORDER BY 1\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "payment_pd = payment_sf.to_pandas()\n",
        "payment_pd[\"MONTH_INDEX\"] = (payment_pd[\"PAYMENT_MONTH\"] - payment_pd[\"PAYMENT_MONTH\"].min()).dt.days / 30\n",
        "payment_pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = payment_pd[[\"MONTH_INDEX\", \"ACTIVE_LOANS\"]]\n",
        "y = payment_pd[\"TOTAL_PAYMENTS\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "payment_model = LinearRegression()\n",
        "payment_model.fit(X_train, y_train)\n",
        "print(\"R^2 on holdout:\", payment_model.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payment_model.save(session=session,\n",
        "                   name=\"PAYMENT_VOLUME_FORECASTER\",\n",
        "                   version_name=\"v1\",\n",
        "                   replace=True)\n",
        "\n",
        "prediction_example = payment_model.predict(X_test.head(5))\n",
        "pd.DataFrame({\n",
        "    \"MONTH_INDEX\": X_test.head(5)[\"MONTH_INDEX\"],\n",
        "    \"ACTIVE_LOANS\": X_test.head(5)[\"ACTIVE_LOANS\"],\n",
        "    \"PREDICTED_PAYMENTS\": prediction_example\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Borrower Risk Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_sf = session.sql(\n",
        "    f\"\"\"\n",
        "    SELECT\n",
        "        c.customer_id,\n",
        "        c.credit_score,\n",
        "        c.annual_income,\n",
        "        COALESCE(SUM(l.outstanding_principal), 0) AS total_outstanding,\n",
        "        COUNT_IF(l.servicing_status = 'DELINQUENT') AS delinquent_loans\n",
        "    FROM {DATABASE}.{SCHEMA}.CUSTOMERS c\n",
        "    LEFT JOIN {DATABASE}.{SCHEMA}.LOAN_ACCOUNTS l ON c.customer_id = l.customer_id\n",
        "    GROUP BY 1,2,3\n",
        "    HAVING COUNT(*) > 0\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "risk_pd = risk_sf.to_pandas()\n",
        "risk_pd[\"TARGET_AT_RISK\"] = (risk_pd[\"DELINQUENT_LOANS\"] > 0).astype(int)\n",
        "risk_pd.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_cols = [\"CREDIT_SCORE\", \"ANNUAL_INCOME\", \"TOTAL_OUTSTANDING\"]\n",
        "X = risk_pd[feature_cols]\n",
        "y = risk_pd[\"TARGET_AT_RISK\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=7, stratify=y)\n",
        "\n",
        "risk_model = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=7)\n",
        "risk_model.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", risk_model.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_model.save(session=session,\n",
        "                 name=\"BORROWER_RISK_MODEL\",\n",
        "                 version_name=\"v1\",\n",
        "                 replace=True)\n",
        "\n",
        "risk_probs = risk_model.predict_proba(X_test.head(5))[:, 1]\n",
        "pd.DataFrame({\n",
        "    \"CUSTOMER_ID\": risk_pd.iloc[X_test.head(5).index][\"CUSTOMER_ID\"],\n",
        "    \"P_DEFAULT\": risk_probs\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Collections Promise-to-Pay Success\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "collections_sf = session.sql(\n",
        "    f\"\"\"\n",
        "    SELECT\n",
        "        l.loan_id,\n",
        "        l.delinquency_bucket,\n",
        "        l.outstanding_principal,\n",
        "        COUNT(DISTINCT p.payment_id) AS payment_count,\n",
        "        AVG(p.amount) AS avg_payment,\n",
        "        COUNT_IF(c.promise_to_pay_date IS NOT NULL) AS ptp_events,\n",
        "        COUNT_IF(c.outcome = 'PAYMENT_MADE') AS immediate_payments,\n",
        "        MAX(CASE WHEN c.promise_to_pay_date IS NOT NULL THEN 1 ELSE 0 END) AS target_ptp\n",
        "    FROM {DATABASE}.{SCHEMA}.LOAN_ACCOUNTS l\n",
        "    LEFT JOIN {DATABASE}.{SCHEMA}.PAYMENT_HISTORY p ON l.loan_id = p.loan_id\n",
        "    LEFT JOIN {DATABASE}.{SCHEMA}.COLLECTION_EVENTS c ON l.loan_id = c.loan_id\n",
        "    WHERE l.servicing_status <> 'CHARGED_OFF'\n",
        "    GROUP BY 1,2,3\n",
        "    HAVING payment_count > 0\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "collections_pd = collections_sf.to_pandas()\n",
        "collections_pd.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "collections_features = pd.get_dummies(collections_pd, columns=[\"DELINQUENCY_BUCKET\"], dummy_na=True)\n",
        "feature_cols = [col for col in collections_features.columns if col.startswith(\"DELINQUENCY_BUCKET_\")]\n",
        "feature_cols += [\"OUTSTANDING_PRINCIPAL\", \"PAYMENT_COUNT\", \"AVG_PAYMENT\", \"PTP_EVENTS\", \"IMMEDIATE_PAYMENTS\"]\n",
        "\n",
        "X = collections_features[feature_cols]\n",
        "y = collections_features[\"TARGET_PTP\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11, stratify=y)\n",
        "\n",
        "ptp_model = LogisticRegression(max_iter=200)\n",
        "ptp_model.fit(X_train, y_train)\n",
        "print(\"ROC-AUC:\", ptp_model.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ptp_model.save(session=session,\n",
        "                name=\"COLLECTION_SUCCESS_MODEL\",\n",
        "                version_name=\"v1\",\n",
        "                replace=True)\n",
        "\n",
        "ptp_scores = ptp_model.predict_proba(X_test.head(5))[:, 1]\n",
        "pd.DataFrame({\n",
        "    \"LOAN_ID\": collections_pd.iloc[X_test.head(5).index][\"LOAN_ID\"],\n",
        "    \"P_PROMISE_TO_PAY\": ptp_scores\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notebook Completion\n",
        "\n",
        "After all cells run successfully:\n",
        "\n",
        "1. Confirm the three models (`PAYMENT_VOLUME_FORECASTER`, `BORROWER_RISK_MODEL`, `COLLECTION_SUCCESS_MODEL`) exist in the Snowflake Model Registry.\n",
        "2. Execute `sql/ml/07_create_model_wrapper_functions.sql` to expose them as stored procedures.\n",
        "3. Re-run `sql/agent/08_create_intelligence_agent.sql` if you want the agent to immediately reference the refreshed models.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
